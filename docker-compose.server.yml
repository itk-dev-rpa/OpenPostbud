networks:
  frontend:
    external: true
  app:
    driver: bridge
    internal: false
  qdrantnet:
    external: true

services:
  nginx:
    image: nginxinc/nginx-unprivileged:alpine
    restart: unless-stopped
    networks:
      - app
      - frontend
    depends_on:
      - api
    ports:
      - '8080'
    volumes:
      - ./.docker/templates:/etc/nginx/templates:ro
      - ./ui:/app
    environment:
      NGINX_WEB_ROOT: /app
      NGINX_PORT: 8080
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=frontend"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}-http.rule=Host(`${COMPOSE_SERVER_DOMAIN}`)"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}-http.entrypoints=web"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}-http.middlewares=redirect-to-https"
      - "traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}.rule=Host(`${COMPOSE_SERVER_DOMAIN}`)"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}.entrypoints=websecure"
      # Add basic protection to prompt editing.
      - "traefik.http.middlewares.admin-auth.basicauth.users=${ADMIN_AUTH}"
      - "traefik.http.middlewares.admin-auth.basicauth.realm=Admin"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}-admin.rule=Host(`${COMPOSE_SERVER_DOMAIN}`) && PathPrefix(`/admin`)"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}-admin.middlewares=admin-auth"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}-edit.rule=Host(`${COMPOSE_SERVER_DOMAIN}`) && PathPrefix(`/api/edit`)"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}-edit.middlewares=admin-auth"

  api:
    build:
      context: .
      dockerfile: .docker/api/Dockerfile
      args:
        - "REQTYPE=-server"
    restart: unless-stopped
    networks:
      - app
      - qdrantnet
    depends_on:
      - whisper
      - tts
    environment:
      - CONTAINER_EMBEDDING_MODEL_PATH=/model
      - GEN_MODEL_URL=${GEN_MODEL_URL:-http://vllm:8000/v1/chat/completions}
      - VECTOR_DB_URL=http://qdrant:6333
      - VECTOR_DB_API_KEY=${VECTOR_DB_API_KEY}
      - VLLM_API_KEY=${VLLM_API_KEY}
    volumes:
      # The model is need to be mapped to get the config.json file.
      - ./vectorstores/intfloat/multilingual-e5-large/:/model
      - ./logs:/logs
      - ./src/prompts:/app/prompts:rw

  whisper:
    image: onerahmet/openai-whisper-asr-webservice:v1.4.1-gpu
    restart: unless-stopped
    networks:
      - app
    environment:
      - ASR_ENGINE=faster_whisper
      - ASR_MODEL=medium
    volumes:
      - .docker/data/whisper:/root/.cache/whisper
    # Add support for GPU on the server.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  tts:
    build:
      context: .
      dockerfile: .docker/tts/Dockerfile
    restart: unless-stopped
    networks:
      - app
    environment:
      - TRANSFORMERS_CACHE=/app/cache
    volumes:
      - .docker/data/tts:/app/cache
      - ./logs:/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
